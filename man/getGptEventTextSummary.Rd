% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/getGptEventTextSummary.R
\name{getGptEventTextSummary}
\alias{getGptEventTextSummary}
\title{Summarise long text vectors using chunked GPT API calls and final aggregation}
\usage{
getGptEventTextSummary(
  event.text.vec,
  token,
  base.url,
  model,
  api.type,
  max.tokens = 1e+05,
  response.max.tokens = 2048,
  max.retries = 3,
  retry.delay = 1,
  system.prompt1 = NULL,
  user.prompt1.intro = NULL,
  system.prompt2 = NULL,
  user.prompt2.intro = NULL
)
}
\arguments{
\item{event.text.vec}{Character vector of input text entries (e.g., event descriptions)}

\item{token}{Character. API authentication token}

\item{base.url}{Character. API base URL}

\item{model}{Character. Model name (e.g., "gpt-4o")}

\item{api.type}{Character. API type parameter for jrcgpt::getGptApiResponse}

\item{max.tokens}{Integer. Approximate max tokens per chunk **input** (default 100000)}

\item{response.max.tokens}{Integer. Max tokens for each GPT **response** (default 2048)}

\item{max.retries}{Integer. Maximum number of retry attempts for failed API calls (default 3)}

\item{retry.delay}{Numeric. Delay in seconds between retry attempts (default 1)}

\item{system.prompt1}{Character. System prompt for first (chunk) pass. Default provided if NULL}

\item{user.prompt1.intro}{Character. Intro text prepended to each chunk's user prompt. Default if NULL}

\item{system.prompt2}{Character. System prompt for final aggregation pass. Default provided if NULL}

\item{user.prompt2.intro}{Character. Intro text prepended to the final user prompt. Default if NULL}
}
\value{
List with:
  - intermediate.summaries (character vector of per-chunk summaries)
  - final.summary (character scalar with final aggregated summary)
}
\description{
Summarise long text vectors using chunked GPT API calls and final aggregation
}
